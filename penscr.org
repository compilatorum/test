#+TITLE: Projeto SLM - Revis√£o Sistem√°tica e Explica√ß√µes ELI5
#+AUTHOR: Manus
#+DATE: <2025-08-17 Sat>
#+OPTIONS: toc:nil num:nil
#+PROPERTY: header-args:python :results output :exports both

* Revis√£o Sistem√°tica sobre Small Language Models (SLMs)
** DONE Resumo Executivo
Small Language Models (SLMs) ‚Äî tipicamente entre 100M e 13B de par√¢metros ‚Äî t√™m avan√ßado ao combinar tr√™s frentes: arquiteturas e infer√™ncia eficientes, compress√£o/transfer√™ncia de conhecimento de LLMs, e integra√ß√£o com fontes externas (RAG e ferramentas). Em tarefas focadas, SLMs bem ajustados igualam ou superam LLMs maiores, com melhor lat√™ncia, custo e privacidade. Os melhores resultados surgem de pipelines que unem dados curados, distila√ß√£o forte, quantiza√ß√£o de baixa precis√£o e RAG, priorizando m√©tricas de utilidade e robustez ao lado de velocidade e energia.
*** Resposta:

** DONE Metodologia Sistem√°tica
*** DONE Objetivo: Mapear evid√™ncias sobre como projetar, treinar e implantar SLMs com alto desempenho pr√°tico em tarefas gerais e espec√≠ficas.
**** Resposta:

*** DONE Perguntas de pesquisa:
Quais estrat√©gias tornam SLMs competitivos em qualidade vs. LLMs maiores?
Quais s√£o os trade‚Äëoffs de custo, lat√™ncia, energia e privacidade?
Quais lacunas existem em avalia√ß√£o, seguran√ßa e uso em dispositivos?
**** Resposta:

*** DONE Crit√©rios de inclus√£o:
Estudos 2022‚Äì2025; peer‚Äëreview e preprints; escopo: SLMs, compress√£o (distila√ß√£o, quantiza√ß√£o, poda), arquiteturas eficientes (Transformers eficientes, SSMs), RAG, avalia√ß√£o, on‚Äëdevice.
**** Resposta:

*** DONE Crit√©rios de exclus√£o:
Trabalhos sem resultados emp√≠ricos, ou apenas te√≥ricos sem implica√ß√µes pr√°ticas; estudos exclusivamente sobre LLMs >70B sem componente de transfer√™ncia para SLMs.
**** Resposta:

*** DONE Strings de Busca (Google Scholar)
**** C√≥digo:
#+begin_src python
print('''
"small language models" OR "SLM" AND "distillation" | "quantization" | "pruning" | "RAG" | "edge" | "on-device" | "SSM" | "Mixture-of-Experts"
"efficient transformer" AND "inference" AND "KV cache" | "speculative decoding" | "flash attention"
"instruction tuning" OR "preference distillation" OR "DPO" AND "small model"
''')
#+end_src

#+RESULTS:

**** Resposta:

*** DONE Triagem e extra√ß√£o:
Triagem t√≠tulo/abstract: relev√¢ncia para SLMs e resultados quantitativos.
Extra√ß√£o: dataset/tarefa, tamanho do modelo, t√©cnica, m√©tricas (ex.: exatid√£o, lat√™ncia p50/p95, energia), ambiente (GPU/CPU/NPU; mem√≥ria; quantiza√ß√£o), riscos/safety.
**** Resposta:

*** DONE Avalia√ß√£o de qualidade:
Reprodutibilidade: c√≥digo/modelos dispon√≠veis; detalhes de hardware.
Validade externa: variedade de tarefas/dom√≠nios/idiomas; abla√ß√£o de componentes.
Medi√ß√µes completas: qualidade + custo + lat√™ncia + energia.
**** Resposta:

** DONE S√≠ntese dos Achados (Estado-da-Arte)
*** DONE Taxonomia de Estrat√©gias
**** DONE Arquiteturas e aten√ß√£o eficientes:
Transformers eficientes: otimiza√ß√µes de aten√ß√£o (Flash/Memory‚Äëefficient), KV‚Äëcache com compress√£o e t√©cnicas como attention sinks; decodifica√ß√£o especulativa para reduzir tokens por passo.
Modelos de estado (SSMs): variantes tipo Mamba melhoram throughput e uso de mem√≥ria em contextos longos, com qualidade competitiva em tarefas sequenciais.
***** Resposta:

**** DONE Compress√£o e transfer√™ncia de conhecimento:
Distila√ß√£o (supervisionada/prefer√™ncias): transfere capacidades de LLMs, preservando instru√ß√£o e alinhamento. Combinar dados sint√©ticos e humanos melhora robustez.
Quantiza√ß√£o (8/4/3‚Äëbit) e poda estruturada: reduzem mem√≥ria/lat√™ncia com degrada√ß√£o m√≠nima quando calibradas e com QLoRA/awq‚Äëstyle quantization‚Äëaware finetuning.
Low‚Äërank e adapters (LoRA/QLoRA): habilitam ajuste eficiente por dom√≠nio em GPUs acess√≠veis e at√© em edge com NPUs.
***** Resposta:

**** DONE Integra√ß√£o com conhecimento externo:
RAG e ferramentas: SLM + busca/BDs/planilhas/c√≥digo compensa lacunas param√©tricas; desempenho melhora substancialmente em QA, gera√ß√£o factual e tarefas empresariais.
Orquestra√ß√£o: pipelines com re‚Äëranking, verifica√ß√£o de cita√ß√µes e cr√≠tica autom√°tica (self‚Äëcheck) reduzem alucina√ß√µes.
***** Resposta:

**** DONE Dados e alinhamento:
Curadoria de dados de alta qualidade: deduplica√ß√£o, filtragem de ru√≠do e balanceamento por idioma/tarefa rendem ganhos equivalentes a aumentos significativos de par√¢metros.
T√©cnicas de alinhamento leve: DPO, KTO e preference distillation adaptam SLMs para estilo/seguran√ßa sem custo elevado.
***** Resposta:

**** DONE Implanta√ß√£o e sistemas:
On‚Äëdevice e edge: SLMs de 1‚Äì3B quantizados a 4‚Äëbit rodam com lat√™ncia interativa em dispositivos modernos; 7B requerem otimiza√ß√µes agressivas e mem√≥ria ‚â•12‚Äì16 GB no lado servidor.
Privacidade/seguran√ßa: processamento local reduz exposi√ß√£o de dados; por√©m exige mitiga√ß√£o de ataques por extra√ß√£o de par√¢metros e membership inference.
***** Resposta:

** DONE Observa√ß√µes de Desempenho e Trade-offs Pr√°ticos
*** DONE Tarefas focadas vs. gerais: SLMs especializados superam LLMs gen√©ricos em dom√≠nios estreitos (por exemplo, suporte interno, rotinas de neg√≥cio, consultas estruturadas) quando h√° RAG + ajuste fino de alta qualidade.
**** Resposta:

*** DONE Leis de escala com ‚Äúajudas‚Äù: Para SLMs, ganhos de dados e engenharia de prompts/pipelines (verifica√ß√£o, vota√ß√£o, auto‚Äëreflex√£o barata) substituem parcialmente escala de par√¢metros.
**** Resposta:

*** DONE Custo e energia: Menores custos por chamada e menor consumo permitem volume alto e SLOs r√≠gidos; ainda assim, quantiza√ß√£o extrema pode degradar racioc√≠nio aritm√©tico/cadeia‚Äëde‚Äëpensamento, exigindo calibragem e, √†s vezes, decodifica√ß√£o especulativa com modelos guias.
**** Resposta:

** DONE Tabela de Estrat√©gias e Trade-offs
*** Tabela:
| Estrat√©gia | O que √© | Benef√≠cio principal | Trade-off t√≠pico | Quando usar |
|------------|---------|---------------------|------------------|-------------|
| Distila√ß√£o de LLM | Transferir conhecimento de um LLM para um SLM | Qualidade pr√≥xima ao teacher | Pode herdar vieses/erros do teacher | Ao criar SLM geral de alta qualidade |
| Quantiza√ß√£o 8/4-bit | Reduzir precis√£o de pesos/ativa√ß√µes | Menor mem√≥ria e lat√™ncia | Perda de precis√£o em tarefas sens√≠veis | Em produ√ß√£o com restri√ß√µes de custo |
| RAG | Recuperar conhecimento externo no momento da consulta | Melhora factualidade e atualiza√ß√£o | Depend√™ncia de indexa√ß√£o/lat√™ncia de busca | Em dom√≠nios com bases atualizadas |
| Adapters (LoRA/QLoRA) | Camadas de baixo custo para ajuste fino | Customiza√ß√£o r√°pida e barata | Pode limitar capacidade em tarefas novas | Para m√∫ltiplos dom√≠nios/clientes |
| Aten√ß√£o/decodifica√ß√£o eficiente | KV-cache, Flash-Attention, especulativa | Acelera√ß√£o sem rebaixar qualidade | Complexidade de engenharia | Em workloads de alta QPS |

*** Resposta:

** DONE Aplica√ß√µes e Recomenda√ß√µes Pr√°ticas
*** DONE Quando escolher SLMs
Restri√ß√µes de lat√™ncia/custo:
Cen√°rio: chat interno, automa√ß√£o, triagem, classifica√ß√£o.
Recomenda√ß√£o: SLM 1‚Äì3B com quantiza√ß√£o 4‚Äëbit e RAG; alvo de p95 < 300 ms em servidores modestos.
Privacidade/on‚Äëdevice (Android 13/edge):
Cen√°rio: dados sens√≠veis, uso offline, responsividade local.
Recomenda√ß√£o: SLM ‚â§3B com quantiza√ß√£o 4‚Äëbit; usar acelera√ß√£o via NPU/GPU quando dispon√≠vel; limitar contexto para estabilidade.
Dom√≠nio estreito e dados propriet√°rios:
Cen√°rio: perguntas frequentes, formul√°rios, relat√≥rios.
Recomenda√ß√£o: ajuste fino com LoRA + RAG; valida√ß√£o com checagem de fontes e guardrails.
**** Resposta:

*** DONE Boas pr√°ticas de pipeline
Dados: curadoria forte, deduplica√ß√£o, balanceamento por idioma (incluindo PT‚ÄëBR), gera√ß√£o sint√©tica com verifica√ß√£o humana amostral.
Treino/ajuste: distila√ß√£o do teacher escolhido para a tarefa; abla√ß√µes para escolher bit‚Äëwidth; LoRA por dom√≠nio.
Infer√™ncia: KV‚Äëcache, batching din√¢mico, top‚Äëk/top‚Äëp calibrados por tarefa; especulativa quando poss√≠vel.
Avalia√ß√£o: qualidade (exatid√£o/factualidade), lat√™ncia p50/p95, custo por 1k tokens, energia, robustez (mudan√ßa de distribui√ß√£o), seguran√ßa (bloqueios e filtros).
**** Resposta:

*** DONE Lacunas e agenda de pesquisa
Generaliza√ß√£o sob restri√ß√£o: entender limites de racioc√≠nio multietapas e sistematicidade em SLMs quantizados.
Seguran√ßa e alinhamento leve: m√©todos de prefer√™ncia eficientes que mantenham seguran√ßa sem perder utilidade em baixa precis√£o.
Multilinguismo real: cobertura robusta para PT‚ÄëBR e dom√≠nios t√©cnicos, com m√©tricas que reflitam uso em produ√ß√£o.
RAG confi√°vel: redu√ß√£o de alucina√ß√µes com checagens e atribui√ß√µes verific√°veis sem sacrificar lat√™ncia.
Medi√ß√µes padronizadas: benchmarks que combinem qualidade, custo, lat√™ncia e energia de forma compar√°vel entre papers.
**** Resposta:

** DONE Como replicar no Google Scholar (passo a passo)
Definir escopo e per√≠odo:
2022‚Äì2025; SLMs, compress√£o, RAG, on‚Äëdevice.
Executar buscas principais:
Use as strings de busca listadas acima; aplique ‚ÄúBuscar em qualquer lugar do artigo‚Äù.
Filtrar e organizar:
Planilha: t√≠tulo, ano, t√©cnica, tamanho do modelo, dados, m√©tricas, ambiente, achados‚Äëchave, limita√ß√µes.
Triagem sistem√°tica:
Etapa 1: t√≠tulo/abstract por relev√¢ncia; Etapa 2: leitura completa; registre motivos de exclus√£o.
Extra√ß√£o e s√≠ntese:
Preencha a planilha; crie tabelas de compara√ß√£o (t√©cnica vs. ganhos vs. custos); identifique padr√µes e lacunas.
Valida√ß√£o:
Reaplique as buscas com ‚ÄúOrdenar por data‚Äù; adicione alertas; pe√ßa revis√£o por pares internos.

üí° Dica: no Scholar, ative ‚ÄúAlertas‚Äù para cada string e use os filtros ‚ÄúDesde 2022‚Äù, ‚ÄúOrdenar por data‚Äù para capturar o estado‚Äëda‚Äëarte de forma cont√≠nua.
*** Resposta:

** DONE Mini-guia de Escolha por Tamanho do Modelo
*** Tabela:
| Faixa de par√¢metros | Implanta√ß√£o t√≠pica | Lat√™ncia esperada | Casos ideais | Observa√ß√µes |
|--------------------|--------------------|-------------------|--------------|-------------|
| 0.3‚Äì1B | On-device/edge | Muito baixa | Classifica√ß√£o, extra√ß√£o, regras | Excelente custo; limitado em racioc√≠nio |
| 1‚Äì3B | Edge/servidor leve | Baixa | Chat assistivo com RAG, suporte | Bom equil√≠brio ap√≥s distila√ß√£o |
| 7‚Äì13B | Servidor | M√©dia | Gera√ß√£o rica, code assist, an√°lise | Exige mem√≥ria; melhor qualidade geral |

*** Resposta:

* Explica√ß√£o ELI5 com Emojis
** DONE O que s√£o SLMs? ü§ñ
Imagine que os SLMs s√£o mini c√©rebros de IA üß† que conseguem entender e responder perguntas, escrever textos, traduzir, e muito mais ‚Äî mas s√£o pequenos, r√°pidos e econ√¥micos!
üêò LLMs (Large Language Models) s√£o grand√µes, tipo um elefante: super inteligentes, mas lentos e caros.
üê≠ SLMs s√£o tipo ratinhos espertos: menores, mas √°geis e eficientes!
üëâ Eles t√™m entre 100 milh√µes e 13 bilh√µes de neur√¥nios (par√¢metros). Isso √© muito, mas ainda bem menos que os gigantes como GPT-4.
*** Resposta:

** DONE Como os SLMs aprendem? üß©
*** DONE Distila√ß√£o (ensinando com um professor)
Um modelo grande ensina um pequeno, tipo um professor üë®‚Äçüè´ explicando para um aluno.
Exemplo: GPT-4 ensina um modelo menor a responder bem.
üß† Dica: use dados bons e variados para o aluno aprender direitinho!
**** Resposta:

*** DONE Quantiza√ß√£o (ficar mais leve)
√â como comprimir o modelo, trocando n√∫meros grandes por pequenininhos.
Exemplo: usar n√∫meros de 8 ou 4 bits em vez de 32.
‚ö†Ô∏è Cuidado: se comprimir demais, ele pode esquecer como fazer contas ou pensar direito.
**** Resposta:

*** DONE RAG (buscar ajuda fora)
O modelo consulta uma biblioteca externa üìñ quando n√£o sabe algo.
Exemplo: ele procura no Google ou em um banco de dados antes de responder.
üí° Dica: combine com filtros para evitar respostas erradas (alucina√ß√µes).
**** Resposta:

** DONE Jarg√µes Explicados com Emojis üõ†Ô∏è
*** Tabela:
| Jarg√£o | Significado simples | Emoji explica√ß√£o |
|--------|---------------------|------------------|
| Distila√ß√£o | Ensinar um modelo pequeno com ajuda de um grande | üë®‚Äçüè´‚û°Ô∏èüë∂ |
| Quantiza√ß√£o | Deixar o modelo mais leve trocando n√∫meros grandes por pequenos | üßÆüîß |
| RAG | Buscar informa√ß√£o externa antes de responder | üîçüìö |
| LoRA/QLoRA | Adicionar ‚Äúcamadas extras‚Äù para ensinar o modelo sem mudar tudo | üßÖüéì |
| KV Cache | Guardar mem√≥ria para n√£o repetir trabalho | üß†üíæ |
| Speculative Decoding | Chutar respostas r√°pidas e corrigir depois | üèÉ‚Äç‚ôÇÔ∏èü§î‚úÖ |
| Flash Attention | Aten√ß√£o turbo para ler mais r√°pido | ‚ö°üëÄ |
| SSM (State Space Models) | Modelos que lembram melhor sequ√™ncias | üßµüß† |

*** Resposta:

** DONE Exemplos Pr√°ticos üß™
*** DONE Android 13 com IA local
Quer rodar IA no celular sem internet? Use um SLM de at√© 3B com quantiza√ß√£o 4-bit.
Exemplo: um app de tradu√ß√£o ou assistente pessoal que funciona offline üì¥.
**** Resposta:

*** DONE Empresa com dados internos
Use SLM com RAG para responder perguntas sobre documentos da empresa.
Exemplo: ‚ÄúQual √© o prazo do contrato X?‚Äù ‚Üí IA busca no PDF e responde.
**** Resposta:

*** DONE Estudante ou pesquisador
Use distila√ß√£o para criar um modelo pequeno que entende bem sua √°rea (ex: biologia üß¨).
Dica: treine com textos da √°rea e revise as respostas com especialistas.
**** Resposta:

** DONE Boas Pr√°ticas com Dicas Simples üí°
*** DONE Treinamento
Use dados limpos e variados üßºüìä.
Misture textos reais com exemplos sint√©ticos (gerados por IA) ü§ñ‚úçÔ∏è.
**** Resposta:

*** DONE Ajuste fino (fine-tuning)
Use LoRA para ensinar o modelo sem gastar muito üí∏.
Fa√ßa testes com diferentes tamanhos e bits para achar o equil√≠brio ‚öñÔ∏è.
**** Resposta:

*** DONE Infer√™ncia (usar o modelo)
Ative KV Cache para acelerar üß†üí®.
Use speculative decoding para respostas mais r√°pidas üèéÔ∏è.
**** Resposta:

*** DONE Seguran√ßa
Filtre respostas perigosas ou erradas com regras simples üö´üß†.
Evite que o modelo memorize dados sens√≠veis üïµÔ∏è‚Äç‚ôÇÔ∏è.
**** Resposta:

** DONE Quando usar SLMs? üß≠
*** Tabela:
| Situa√ß√£o | Use SLM? | Por qu√™ |
|----------|----------|---------|
| üí¨ Chat interno | ‚úÖ | Respostas r√°pidas e baratas |
| üì± App offline | ‚úÖ | Funciona sem internet |
| üß† Tarefa complexa | ‚ö†Ô∏è | Pode precisar de modelo maior |
| üßæ Dados privados | ‚úÖ | Mais seguro se rodar localmente |

*** Resposta:

** DONE Resumo com Analogia üß†
Aprendem com professores grandes üë®‚Äçüè´
Ficam leves com dieta de bits üßÆ
Buscam ajuda quando precisam üîç
Trabalham r√°pido e barato üí®üí∏
Eles n√£o sabem tudo, mas com bons dados e truques, podem fazer muito!
*** Resposta:

* Como montar seu pr√≥prio SLM no Android 13 üß†
** DONE Escolha o modelo certo üß±
Use um modelo pequeno, tipo Phi-2, Gemma 2B, ou Mistral 7B.
Para Android, o ideal √© at√© 3B com quantiza√ß√£o 4-bit.
*** C√≥digo:
#+begin_src plaintext
Modelo: Gemma 2B  
Quantiza√ß√£o: 4-bit  
Tamanho final: ~1.2GB
#+end_src

#+RESULTS:

*** Resposta:

** DONE Use quantiza√ß√£o para caber no celular üßÆ
Ferramentas como GGUF ou GPTQ ajudam a comprimir o modelo.
Isso reduz o uso de mem√≥ria e acelera a resposta.
üí° Dica:
Use quantiza√ß√£o int4 para rodar em celulares com 6GB de RAM ou mais.
*** Resposta:
** DONE Adicione LoRA para ensinar coisas novas üß†
LoRA √© como colocar uma ‚Äúmochila de conhecimento‚Äù no modelo üéí.
Voc√™ pode treinar com frases em portugu√™s, g√≠rias mineiras üòÑ, ou comandos espec√≠ficos.
*** C√≥digo:
#+begin_src plaintext
Treinamento: "Como est√° o tempo em BH?" ‚Üí Resposta: "Hoje t√° quente, uai! ‚òÄÔ∏è"
#+end_src

#+RESULTS:

*** Resposta:
** DONE Use RAG para buscar dados locais üîç
Combine com um banco de dados ou arquivos PDF no celular.
O modelo consulta os dados antes de responder.
üìÅ Exemplo:
Voc√™ pergunta: ‚ÄúQual √© o vencimento da fatura da Claro?‚Äù
‚Üí Ele busca no PDF salvo e responde: ‚ÄúDia 10 de cada m√™s.‚Äù
*** Resposta:

** DONE Acelere com KV Cache e Speculative Decoding
KV Cache guarda o que j√° foi dito, evitando repetir trabalho.
Speculative Decoding faz o modelo ‚Äúchutar‚Äù a resposta e corrigir depois.
üí° Dica:
Essas t√©cnicas deixam o modelo at√© 2x mais r√°pido!
*** Resposta:

** DONE Ferramentas √∫teis para voc√™ testar üß™
*** Tabela:
| Ferramenta | Fun√ß√£o | Emoji explica√ß√£o |
|------------|--------|------------------|
| LM Studio | Interface para rodar modelos localmente | üñ•Ô∏èüß† |
| Ollama | Gerenciador de modelos com comandos simples | ‚öôÔ∏èüì¶ |
| GGUF | Formato leve para modelos quantizados | üßÆüìÅ |
| LoRA Trainer | Treinar modelos com dados personalizados | üéìüßµ |

*** Resposta:

** DONE Exemplo de uso: Assistente ‚ÄúJo√£oGPT‚Äù ü§†
Imagine um app que voc√™ abre e pergunta:
‚ÄúJo√£o, qual o resumo das reuni√µes de hoje?‚Äù
‚Üí O SLM busca nas suas anota√ß√µes e te d√° um resumo r√°pido.

*** Resposta:

* Espa√ßo para C√≥digos e Respostas
** C√≥digo 1
#+begin_src python
# Seu c√≥digo aqui
# Exemplo:
# print("Hello, Org Babel!")
#+end_src

#+RESULTS:

** Resposta 1

** C√≥digo 2
#+begin_src python
# Seu c√≥digo aqui
# Exemplo:
# a = 10
# b = 20
# print(a + b)
#+end_src

#+RESULTS:

** Resposta 2




** DONE Fontes
*** Resposta:
Sintetizado da literatura recente e pr√°ticas de engenharia de modelos.

